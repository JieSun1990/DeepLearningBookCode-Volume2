{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>\n",
    "Copyright (c) 2017 Andrew Glassner\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "</small>\n",
    "\n",
    "\n",
    "\n",
    "# Deep Learning From Basics to Practice\n",
    "## by Andrew Glassner, https://dlbasics.com, http://glassner.com\n",
    "------\n",
    "## Chapter 21: Convolutional Neural Networks (CNNs)\n",
    "### Notebook 6: Adversarial images \n",
    "\n",
    "This notebook is provided as a “behind-the-scenes” look at code used to make some of the figures in this chapter. It is still in the hacked-together form used to develop the figures, and is only lightly commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import foolbox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Just in case the Keras defaults aren't as we expect\n",
    "from keras import backend as K_backend\n",
    "K_backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a File_Helper for saving and loading files.\n",
    "\n",
    "save_files = True\n",
    "\n",
    "import os, sys, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.insert(0, os.path.dirname(current_dir)) # path to parent dir\n",
    "from DLBasics_Utilities import File_Helper\n",
    "file_helper = File_Helper(save_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = file_helper.get_input_data_dir()\n",
    "sys.path.append(input_dir)\n",
    "import VGG16_syn_indices\n",
    "import VGG16_syn_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the adversarial generator library called Foolbox to make our examples.\n",
    "# Import all of the Foolbox attacks and criteria, so we can try them all later\n",
    "# Foolbox documentation at https://foolbox.readthedocs.io/en/latest\n",
    "from foolbox.attacks import GradientSignAttack, IterativeGradientSignAttack\n",
    "from foolbox.attacks import GradientAttack, IterativeGradientAttack\n",
    "from foolbox.attacks import LBFGSAttack\n",
    "from foolbox.attacks import DeepFoolAttack, SLSQPAttack, SaliencyMapAttack\n",
    "from foolbox.attacks import SinglePixelAttack, LocalSearchAttack, ApproximateLBFGSAttack\n",
    "from foolbox.attacks import BoundaryAttack, GaussianBlurAttack\n",
    "from foolbox.attacks import ContrastReductionAttack, AdditiveUniformNoiseAttack\n",
    "from foolbox.attacks import AdditiveGaussianNoiseAttack, BlendedUniformNoiseAttack\n",
    "from foolbox.attacks import SaltAndPepperNoiseAttack\n",
    "from foolbox.attacks import PrecomputedImagesAttack\n",
    "\n",
    "from foolbox.criteria import Misclassification, TopKMisclassification, OriginalClassProbability\n",
    "from foolbox.criteria import TargetClass, TargetClassProbability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    '''Get the Keras and Foolbox models, based on the Foolbox instructions.'''\n",
    "    keras.backend.set_learning_phase(0) \n",
    "    keras_model = keras.applications.vgg16.VGG16(weights='imagenet')\n",
    "    preprocessing = (np.array([104, 116, 123]), 1)\n",
    "    fb_model = foolbox.models.KerasModel(keras_model, bounds=(0, 255), preprocessing=preprocessing)\n",
    "    return keras_model, fb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "\n",
    "def read_and_prep_image(filepath):\n",
    "    '''Read in an image, set its type to float32, and return it.'''\n",
    "    image = io.imread(filepath)\n",
    "    image = resize(image, (224, 224), order=3, preserve_range=True)\n",
    "    float_image = image.astype('float32')\n",
    "    return float_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image_for_display(image):\n",
    "    '''Floating-point images don't display well, and we might be looking\n",
    "    at images far outside the [0,255] range. So fix them up to look good.'''\n",
    "    img = np.copy(image)\n",
    "    img -= img.mean()\n",
    "    img /= (img.std() + 1e-5)\n",
    "    img *= 64\n",
    "    img += 128\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_float_image(img, filename):\n",
    "    '''Prep the image, show it, and save it with the given name.'''\n",
    "    plt.imshow(prep_image_for_display(img))\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "    file_helper.save_figure(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names_from_predictions(predictions, number_to_return):\n",
    "    '''Get the scores and class names from the list of prediction values.'''\n",
    "    top_list = []\n",
    "    for i in range(number_to_return):\n",
    "        maxarg = np.argmax(predictions)\n",
    "        maxval = predictions[maxarg]\n",
    "        top_list.append([maxarg, maxval])\n",
    "        predictions = [i if i<maxval else -1 for i in predictions]\n",
    "    report_scores = []\n",
    "    report_names = []\n",
    "    for i in top_list:\n",
    "        n_index = VGG16_syn_indices.syn_indices_list[i[0]]\n",
    "        words = VGG16_syn_words.syn_words_dict[n_index]\n",
    "        words = words[:16]  # clip to first 16 chars\n",
    "        report_scores.append(i[1])\n",
    "        report_names.append(words)\n",
    "    return (report_scores, report_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_adversarial_set(keras_model, \n",
    "                         original_image, adversarial_image, delta_image, \n",
    "                         number_of_categories, filename):\n",
    "    '''Plot the original image with scores and classes, the image that we add\n",
    "    to it (scaled to look good), and then the adversarial image with scores and classes.'''\n",
    "\n",
    "    original_predictions = keras_model.predict(np.expand_dims(original_image, axis=0))[0]\n",
    "    (report_scores, report_names) = names_from_predictions(original_predictions, number_of_categories) \n",
    "    report_names = [f.split(',')[0] for f in report_names]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    #fig.subplots_adjust(wspace=0.0)\n",
    "    \n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(prep_image_for_display(original_image))\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "    plt.subplot(2,3,4)\n",
    "    xs = range(len(report_names))\n",
    "    plt.bar(xs, report_scores, align='center')\n",
    "    plt.xticks(xs, report_names, rotation='-90')\n",
    "    plt.yticks([0,1],[0,1])\n",
    "    plt.tick_params(axis='x', which='major', labelsize=18)\n",
    "    \n",
    "    plt.subplot(2,3,2)    \n",
    "    plt.imshow(prep_image_for_display(delta_image))\n",
    "    title = '({:1.2f}, {:1.2f})'.format(np.min(delta_image), np.max(delta_image))\n",
    "    plt.title(title)\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "    \n",
    "    adversarial_predictions = keras_model.predict(np.expand_dims(adversarial_image, axis=0))[0]\n",
    "    (report_scores, report_names) = names_from_predictions(adversarial_predictions, number_of_categories) \n",
    "    report_names = [f.split(',')[0] for f in report_names]\n",
    "    \n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(prep_image_for_display(adversarial_image))\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "    plt.subplot(2,3,6)\n",
    "    xs = range(len(report_names))\n",
    "    plt.bar(xs, report_scores, align='center')\n",
    "    plt.xticks(xs, report_names, rotation='-90')\n",
    "    plt.yticks([0,1],[0,1])\n",
    "    plt.tick_params(axis='x', which='major', labelsize=18)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    file_helper.save_figure(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_variation(attack_choice, criteria_choice, original_image):\n",
    "    '''Run an adversarial attack of this type on this image.'''\n",
    "    attack_val = attack_dict[attack_choice]\n",
    "    criteria_val = criteria_dict[criteria_choice]\n",
    "    keras_model, fb_model = get_models()\n",
    "    \n",
    "    criteria_func = criteria_val[0]\n",
    "    criteria_args = criteria_val[1]\n",
    "    criteria = criteria_func(**criteria_args)\n",
    "    attacker = attack_val(fb_model, criteria) \n",
    "\n",
    "    predictions = keras_model.predict(np.expand_dims(original_image, axis=0))[0]\n",
    "    # predicted_label is the index of the label, not the label itself, because \n",
    "    # of the 2-step process required to work out VGG16 labels, but the distinction \n",
    "    # isn't important here because this value is still unique and consistent.\n",
    "    predicted_label = np.argmax(predictions)\n",
    "\n",
    "    print('running atttack=',attack_choice,' criteria=',criteria_choice)\n",
    "    adversarial_image = attacker(input_or_adv=original_image, label=predicted_label)\n",
    "    \n",
    "    delta_image = adversarial_image - original_image    \n",
    "    print(\"<<<<<<<<<<< attack was successful! >>>>>>>>>>>>>>>\")\n",
    "    return original_image, adversarial_image, delta_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the attacks, so we can choose one by name. Note that not all\n",
    "# attackers work with all criteria. Each attacker/criteria combo takes\n",
    "# its own amount of time, ranging from seconds to 10's of hours (at least)\n",
    "attack_dict = {\n",
    "   'GradientSignAttack': GradientSignAttack,\n",
    "   'IterativeGradientSignAttack': IterativeGradientSignAttack,\n",
    "   'GradientAttack': GradientAttack,\n",
    "   'IterativeGradientAttack': IterativeGradientAttack,\n",
    "   'LBFGSAttack': LBFGSAttack,\n",
    "   'DeepFoolAttack': DeepFoolAttack,\n",
    "   'SLSQPAttack': SLSQPAttack,\n",
    "   'SaliencyMapAttack': SaliencyMapAttack,\n",
    "   'SinglePixelAttack': SinglePixelAttack,\n",
    "   'LocalSearchAttack': LocalSearchAttack,\n",
    "   'ApproximateLBFGSAttack': ApproximateLBFGSAttack,\n",
    "   'BoundaryAttack': BoundaryAttack,\n",
    "   'GaussianBlurAttack': GaussianBlurAttack,\n",
    "   'ContrastReductionAttack': ContrastReductionAttack,\n",
    "   'AdditiveUniformNoiseAttack': AdditiveUniformNoiseAttack,\n",
    "   'AdditiveGaussianNoiseAttack': AdditiveGaussianNoiseAttack,\n",
    "   'BlendedUniformNoiseAttack': BlendedUniformNoiseAttack,\n",
    "   'SaltAndPepperNoiseAttack': SaltAndPepperNoiseAttack,\n",
    "   'PrecomputedImagesAttack': PrecomputedImagesAttack,\n",
    "}\n",
    "\n",
    "# All of the attack criteria, so we can choose one by name\n",
    "# class 864 = tow truck, 870=tricycle\n",
    "criteria_dict = {\n",
    "    'Misclassification': [Misclassification, {}],\n",
    "    'TopKMisclassification': [TopKMisclassification, {'k': 7}],\n",
    "    'OriginalClassProbability': [OriginalClassProbability, {'p': 0.01}],\n",
    "    'TargetClass': [TargetClass, {'target_class': 870}],\n",
    "    'TargetClassProbability': [TargetClassProbability, {'target_class': 870, 'p': 0.98}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_show_adveraries(attacker, criteria, image_path, single_filname, set_filename):\n",
    "    '''Run this image through the attack process. Show and save\n",
    "    the original image, plus the adversarial set. We will use the\n",
    "    TopKMisclassification criteria, with k=7, so the most likely\n",
    "    class of the adversarial image won't be one of the top 7 classes\n",
    "    assigned to the input.'''\n",
    "    original_image = read_and_prep_image(image_path)\n",
    "    show_float_image(original_image, single_filname)\n",
    "    origX, advX, deltaX = run_variation(attacker, criteria, original_image)\n",
    "    #origX, advX, deltaX = run_variation('BoundaryAttack', 'TopKMisclassification', original_image)\n",
    "    keras_model, fb_model = get_models()\n",
    "    show_adversarial_set(keras_model, origX, advX, deltaX, 5, set_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images we want to find adversaries for\n",
    "\n",
    "attacker = 'GradientSignAttack'\n",
    "criteria = 'TopKMisclassification'\n",
    "\n",
    "image_files = [\n",
    "    ['tiger-1342385_640.jpg', 'adv-tiger-original-GSA-TKM', 'adv-tiger-set-GSA-TKM'],\n",
    "    ['battery-19983_640-sq2.jpg', 'adv-battery-original-GSA-TKM', 'adv-battery-set-GSA-TKM'],\n",
    "    ['bird-1281886_640-sq.jpg', 'adv-bird-original-GSA-TKM', 'adv-bird-set-GSA-TKM'],\n",
    "    ]\n",
    "\n",
    "for (image_name, single_filename, set_filename) in image_files:\n",
    "    image_path = file_helper.get_input_file_path(image_name)\n",
    "    make_and_show_adveraries(attacker, criteria, image_path, single_filename, set_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
